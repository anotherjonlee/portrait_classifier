{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\") ## resetting the path to the parent directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "keras = tf.keras\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10254 images belonging to 12 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "        '../data/train_folder',  # this is the target directory\n",
    "        target_size=(224, 224),  # all images will be resized to 150x150\n",
    "        batch_size=batch_size,\n",
    "        color_mode=\"rgb\",\n",
    "        class_mode='categorical')  # since we use binary_crossentropy loss, we need binary labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1140 images belonging to 12 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        '../data/validation_folder',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "img_width, img_height = 224, 224\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepared_images = preprocess_input(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = VGG16(include_top=False, weights='imagenet',input_shape = (224,224,3),pooling=max)\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "inpt = Input(shape=(224,224,3),name = 'image_input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = base_model(inpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat1 = Flatten(name='flatten')(output)\n",
    "class1 = Dense(1024, activation='relu', name='fc1')(flat1)\n",
    "output = Dense(12, activation='softmax', name='predictions')(class1)\n",
    "# define new model\n",
    "vgg_model = Model(inputs=inpt, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "image_input (InputLayer)     [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "vgg16 (Model)                (None, 7, 7, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 1024)              25691136  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 12)                12300     \n",
      "=================================================================\n",
      "Total params: 40,418,124\n",
      "Trainable params: 25,703,436\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGD(lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model.compile(optimizer=sgd,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = 100\n",
    "epoch  = 500\n",
    "def my_gen(gen):\n",
    "    i=0\n",
    "    while i < steps_per_epoch * epoch:\n",
    "        try:\n",
    "            data, labels = next(gen)\n",
    "            i+=1\n",
    "            yield data, labels\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "100/100 [==============================] - 77s 773ms/step - loss: 2.4267 - accuracy: 0.1391 - val_loss: 2.2895 - val_accuracy: 0.1974\n",
      "Epoch 2/1000\n",
      "100/100 [==============================] - 77s 766ms/step - loss: 2.2099 - accuracy: 0.2422 - val_loss: 2.1299 - val_accuracy: 0.2474\n",
      "Epoch 3/1000\n",
      "100/100 [==============================] - 78s 775ms/step - loss: 2.0938 - accuracy: 0.2747 - val_loss: 1.9978 - val_accuracy: 0.3009\n",
      "Epoch 4/1000\n",
      "100/100 [==============================] - 77s 766ms/step - loss: 1.9797 - accuracy: 0.3174 - val_loss: 1.9143 - val_accuracy: 0.3298\n",
      "Epoch 5/1000\n",
      "100/100 [==============================] - 77s 771ms/step - loss: 1.9182 - accuracy: 0.3434 - val_loss: 1.8346 - val_accuracy: 0.3737\n",
      "Epoch 6/1000\n",
      "100/100 [==============================] - 77s 772ms/step - loss: 1.8415 - accuracy: 0.3625 - val_loss: 1.7455 - val_accuracy: 0.3956\n",
      "Epoch 7/1000\n",
      "100/100 [==============================] - 77s 768ms/step - loss: 1.7969 - accuracy: 0.3843 - val_loss: 1.6769 - val_accuracy: 0.4026\n",
      "Epoch 8/1000\n",
      "100/100 [==============================] - 77s 770ms/step - loss: 1.7485 - accuracy: 0.3894 - val_loss: 1.6798 - val_accuracy: 0.4254\n",
      "Epoch 9/1000\n",
      "100/100 [==============================] - 77s 769ms/step - loss: 1.7168 - accuracy: 0.4069 - val_loss: 1.6191 - val_accuracy: 0.4491\n",
      "Epoch 10/1000\n",
      "100/100 [==============================] - 77s 771ms/step - loss: 1.6770 - accuracy: 0.4092 - val_loss: 1.5469 - val_accuracy: 0.4614\n",
      "Epoch 11/1000\n",
      "100/100 [==============================] - 77s 771ms/step - loss: 1.6201 - accuracy: 0.4225 - val_loss: 1.5653 - val_accuracy: 0.4404\n",
      "Epoch 12/1000\n",
      "100/100 [==============================] - 77s 769ms/step - loss: 1.6039 - accuracy: 0.4253 - val_loss: 1.5373 - val_accuracy: 0.4518\n",
      "Epoch 13/1000\n",
      "100/100 [==============================] - 77s 768ms/step - loss: 1.5792 - accuracy: 0.4393 - val_loss: 1.5160 - val_accuracy: 0.4623\n",
      "Epoch 14/1000\n",
      "100/100 [==============================] - 77s 770ms/step - loss: 1.5490 - accuracy: 0.4434 - val_loss: 1.4820 - val_accuracy: 0.4623\n",
      "Epoch 15/1000\n",
      "100/100 [==============================] - 77s 769ms/step - loss: 1.5173 - accuracy: 0.4653 - val_loss: 1.4652 - val_accuracy: 0.4684\n",
      "Epoch 16/1000\n",
      "100/100 [==============================] - 78s 778ms/step - loss: 1.5089 - accuracy: 0.4676 - val_loss: 1.4253 - val_accuracy: 0.5123\n",
      "Epoch 17/1000\n",
      "100/100 [==============================] - 77s 773ms/step - loss: 1.4856 - accuracy: 0.4709 - val_loss: 1.3923 - val_accuracy: 0.4904\n",
      "Epoch 18/1000\n",
      "100/100 [==============================] - 77s 770ms/step - loss: 1.4540 - accuracy: 0.4787 - val_loss: 1.4951 - val_accuracy: 0.4737\n",
      "Epoch 19/1000\n",
      "100/100 [==============================] - 77s 770ms/step - loss: 1.4663 - accuracy: 0.4800 - val_loss: 1.3447 - val_accuracy: 0.5368\n",
      "Epoch 20/1000\n",
      "100/100 [==============================] - 77s 771ms/step - loss: 1.4314 - accuracy: 0.4981 - val_loss: 1.2958 - val_accuracy: 0.5404\n",
      "Epoch 21/1000\n",
      "100/100 [==============================] - 77s 771ms/step - loss: 1.4275 - accuracy: 0.4878 - val_loss: 1.2956 - val_accuracy: 0.5360\n",
      "Epoch 22/1000\n",
      "100/100 [==============================] - 77s 773ms/step - loss: 1.3900 - accuracy: 0.4969 - val_loss: 1.3023 - val_accuracy: 0.5377\n",
      "Epoch 23/1000\n",
      "100/100 [==============================] - 77s 769ms/step - loss: 1.3797 - accuracy: 0.5170 - val_loss: 1.3048 - val_accuracy: 0.5298\n",
      "Epoch 24/1000\n",
      "100/100 [==============================] - 78s 778ms/step - loss: 1.3907 - accuracy: 0.4953 - val_loss: 1.2620 - val_accuracy: 0.5588\n",
      "Epoch 25/1000\n",
      "100/100 [==============================] - 78s 785ms/step - loss: 1.3408 - accuracy: 0.5116 - val_loss: 1.2509 - val_accuracy: 0.5596\n",
      "Epoch 26/1000\n",
      "100/100 [==============================] - 78s 782ms/step - loss: 1.3606 - accuracy: 0.5226 - val_loss: 1.2310 - val_accuracy: 0.5728\n",
      "Epoch 27/1000\n",
      "100/100 [==============================] - 78s 781ms/step - loss: 1.3483 - accuracy: 0.5213 - val_loss: 1.2963 - val_accuracy: 0.5325\n",
      "Epoch 28/1000\n",
      "100/100 [==============================] - 78s 780ms/step - loss: 1.3023 - accuracy: 0.5341 - val_loss: 1.2536 - val_accuracy: 0.5395\n",
      "Epoch 29/1000\n",
      "100/100 [==============================] - 77s 774ms/step - loss: 1.3187 - accuracy: 0.5336 - val_loss: 1.1914 - val_accuracy: 0.6009\n",
      "Epoch 30/1000\n",
      "100/100 [==============================] - 78s 779ms/step - loss: 1.3166 - accuracy: 0.5381 - val_loss: 1.2743 - val_accuracy: 0.5228\n",
      "Epoch 31/1000\n",
      "100/100 [==============================] - 78s 781ms/step - loss: 1.2831 - accuracy: 0.5378 - val_loss: 1.2105 - val_accuracy: 0.5658\n",
      "Epoch 32/1000\n",
      "100/100 [==============================] - 77s 775ms/step - loss: 1.2812 - accuracy: 0.5352 - val_loss: 1.1678 - val_accuracy: 0.5895\n",
      "Epoch 33/1000\n",
      "100/100 [==============================] - 78s 781ms/step - loss: 1.2937 - accuracy: 0.5337 - val_loss: 1.1891 - val_accuracy: 0.5842\n",
      "Epoch 34/1000\n",
      "100/100 [==============================] - 78s 782ms/step - loss: 1.2746 - accuracy: 0.5375 - val_loss: 1.1584 - val_accuracy: 0.5939\n",
      "Epoch 35/1000\n",
      "100/100 [==============================] - 78s 776ms/step - loss: 1.2714 - accuracy: 0.5402 - val_loss: 1.2182 - val_accuracy: 0.5684\n",
      "Epoch 36/1000\n",
      "100/100 [==============================] - 78s 783ms/step - loss: 1.2488 - accuracy: 0.5506 - val_loss: 1.2132 - val_accuracy: 0.5509\n",
      "Epoch 37/1000\n",
      "100/100 [==============================] - 78s 782ms/step - loss: 1.2338 - accuracy: 0.5584 - val_loss: 1.1784 - val_accuracy: 0.5526\n",
      "Epoch 38/1000\n",
      "100/100 [==============================] - 78s 776ms/step - loss: 1.2437 - accuracy: 0.5500 - val_loss: 1.1772 - val_accuracy: 0.5596\n",
      "Epoch 39/1000\n",
      "100/100 [==============================] - 78s 776ms/step - loss: 1.2157 - accuracy: 0.5619 - val_loss: 1.1279 - val_accuracy: 0.6061\n",
      "Epoch 40/1000\n",
      "100/100 [==============================] - 79s 785ms/step - loss: 1.2117 - accuracy: 0.5672 - val_loss: 1.1169 - val_accuracy: 0.5947\n",
      "Epoch 41/1000\n",
      "100/100 [==============================] - 78s 783ms/step - loss: 1.2284 - accuracy: 0.5475 - val_loss: 1.1429 - val_accuracy: 0.5921\n",
      "Epoch 42/1000\n",
      "100/100 [==============================] - 78s 780ms/step - loss: 1.2346 - accuracy: 0.5471 - val_loss: 1.0859 - val_accuracy: 0.6281\n",
      "Epoch 43/1000\n",
      "100/100 [==============================] - 78s 781ms/step - loss: 1.2121 - accuracy: 0.5631 - val_loss: 1.1071 - val_accuracy: 0.6175\n",
      "Epoch 44/1000\n",
      "100/100 [==============================] - 78s 784ms/step - loss: 1.1878 - accuracy: 0.5656 - val_loss: 1.1051 - val_accuracy: 0.5947\n",
      "Epoch 45/1000\n",
      "100/100 [==============================] - 78s 781ms/step - loss: 1.2148 - accuracy: 0.5581 - val_loss: 1.1340 - val_accuracy: 0.5816\n",
      "Epoch 46/1000\n",
      "100/100 [==============================] - 78s 782ms/step - loss: 1.1954 - accuracy: 0.5691 - val_loss: 1.1268 - val_accuracy: 0.6000\n",
      "Epoch 47/1000\n",
      "100/100 [==============================] - 78s 780ms/step - loss: 1.1693 - accuracy: 0.5781 - val_loss: 1.1279 - val_accuracy: 0.5982\n",
      "Epoch 48/1000\n",
      "100/100 [==============================] - 78s 782ms/step - loss: 1.1752 - accuracy: 0.5823 - val_loss: 1.0782 - val_accuracy: 0.6263\n",
      "Epoch 49/1000\n",
      "100/100 [==============================] - 78s 780ms/step - loss: 1.1562 - accuracy: 0.5825 - val_loss: 1.0538 - val_accuracy: 0.6395\n",
      "Epoch 50/1000\n",
      "100/100 [==============================] - 78s 782ms/step - loss: 1.1597 - accuracy: 0.5853 - val_loss: 1.0540 - val_accuracy: 0.6272\n",
      "Epoch 51/1000\n",
      "100/100 [==============================] - 78s 781ms/step - loss: 1.1779 - accuracy: 0.5710 - val_loss: 1.0801 - val_accuracy: 0.6211\n",
      "Epoch 52/1000\n",
      "100/100 [==============================] - 79s 786ms/step - loss: 1.1597 - accuracy: 0.5766 - val_loss: 1.0778 - val_accuracy: 0.6070\n",
      "Epoch 53/1000\n",
      "100/100 [==============================] - 78s 782ms/step - loss: 1.1682 - accuracy: 0.5728 - val_loss: 1.0521 - val_accuracy: 0.6167\n",
      "Epoch 54/1000\n",
      "100/100 [==============================] - 78s 778ms/step - loss: 1.1640 - accuracy: 0.5786 - val_loss: 1.0315 - val_accuracy: 0.6447\n",
      "Epoch 55/1000\n",
      "100/100 [==============================] - 78s 779ms/step - loss: 1.1303 - accuracy: 0.5919 - val_loss: 1.0758 - val_accuracy: 0.6079\n",
      "Epoch 56/1000\n",
      "100/100 [==============================] - 78s 783ms/step - loss: 1.1523 - accuracy: 0.5894 - val_loss: 1.0124 - val_accuracy: 0.6482\n",
      "Epoch 57/1000\n",
      "100/100 [==============================] - 78s 781ms/step - loss: 1.1138 - accuracy: 0.6031 - val_loss: 1.0686 - val_accuracy: 0.6158\n",
      "Epoch 58/1000\n",
      "100/100 [==============================] - 77s 774ms/step - loss: 1.1443 - accuracy: 0.5855 - val_loss: 1.0333 - val_accuracy: 0.6281\n",
      "Epoch 59/1000\n",
      "100/100 [==============================] - 78s 782ms/step - loss: 1.1295 - accuracy: 0.5931 - val_loss: 1.0491 - val_accuracy: 0.6158\n",
      "Epoch 60/1000\n",
      "100/100 [==============================] - 78s 780ms/step - loss: 1.1108 - accuracy: 0.5919 - val_loss: 0.9980 - val_accuracy: 0.6579\n",
      "Epoch 61/1000\n",
      "100/100 [==============================] - 78s 779ms/step - loss: 1.1170 - accuracy: 0.5915 - val_loss: 0.9883 - val_accuracy: 0.6439\n",
      "Epoch 62/1000\n",
      "100/100 [==============================] - 78s 781ms/step - loss: 1.0951 - accuracy: 0.5978 - val_loss: 1.1042 - val_accuracy: 0.5798\n",
      "Epoch 63/1000\n",
      "100/100 [==============================] - 78s 784ms/step - loss: 1.1141 - accuracy: 0.5987 - val_loss: 1.0312 - val_accuracy: 0.6167\n",
      "Epoch 64/1000\n",
      "100/100 [==============================] - 78s 778ms/step - loss: 1.1174 - accuracy: 0.5993 - val_loss: 0.9996 - val_accuracy: 0.6351\n",
      "Epoch 65/1000\n",
      "100/100 [==============================] - 78s 781ms/step - loss: 1.1047 - accuracy: 0.6078 - val_loss: 1.0134 - val_accuracy: 0.6325\n",
      "Epoch 66/1000\n",
      "100/100 [==============================] - 78s 777ms/step - loss: 1.1009 - accuracy: 0.5994 - val_loss: 1.0077 - val_accuracy: 0.6395\n",
      "Epoch 67/1000\n",
      "100/100 [==============================] - 78s 778ms/step - loss: 1.0939 - accuracy: 0.5977 - val_loss: 1.0207 - val_accuracy: 0.6412\n",
      "Epoch 68/1000\n",
      "100/100 [==============================] - 78s 777ms/step - loss: 1.0921 - accuracy: 0.6078 - val_loss: 0.9657 - val_accuracy: 0.6579\n",
      "Epoch 69/1000\n",
      "100/100 [==============================] - 78s 783ms/step - loss: 1.1009 - accuracy: 0.6056 - val_loss: 0.9722 - val_accuracy: 0.6579\n",
      "Epoch 70/1000\n",
      "100/100 [==============================] - 78s 777ms/step - loss: 1.0823 - accuracy: 0.6087 - val_loss: 1.0070 - val_accuracy: 0.6307\n",
      "Epoch 71/1000\n",
      "100/100 [==============================] - 78s 779ms/step - loss: 1.0808 - accuracy: 0.6037 - val_loss: 1.0000 - val_accuracy: 0.6377\n",
      "Epoch 72/1000\n",
      "100/100 [==============================] - 78s 783ms/step - loss: 1.0934 - accuracy: 0.5959 - val_loss: 0.9858 - val_accuracy: 0.6421\n",
      "Epoch 73/1000\n",
      "100/100 [==============================] - 78s 784ms/step - loss: 1.0792 - accuracy: 0.6097 - val_loss: 1.0019 - val_accuracy: 0.6316\n",
      "Epoch 74/1000\n",
      "100/100 [==============================] - 77s 775ms/step - loss: 1.0647 - accuracy: 0.6162 - val_loss: 1.0081 - val_accuracy: 0.6211\n",
      "Epoch 75/1000\n",
      "100/100 [==============================] - 78s 783ms/step - loss: 1.0406 - accuracy: 0.6278 - val_loss: 0.9798 - val_accuracy: 0.6474\n",
      "Epoch 76/1000\n",
      "100/100 [==============================] - 78s 782ms/step - loss: 1.1031 - accuracy: 0.5919 - val_loss: 1.0294 - val_accuracy: 0.6114\n",
      "Epoch 77/1000\n",
      "100/100 [==============================] - 78s 778ms/step - loss: 1.0663 - accuracy: 0.6018 - val_loss: 0.9684 - val_accuracy: 0.6447\n",
      "Epoch 78/1000\n",
      "100/100 [==============================] - 78s 784ms/step - loss: 1.0475 - accuracy: 0.6250 - val_loss: 0.9905 - val_accuracy: 0.6421\n",
      "Epoch 79/1000\n",
      "100/100 [==============================] - 78s 784ms/step - loss: 1.0790 - accuracy: 0.6112 - val_loss: 1.0092 - val_accuracy: 0.6123\n",
      "Epoch 80/1000\n",
      "100/100 [==============================] - 78s 783ms/step - loss: 1.0544 - accuracy: 0.6207 - val_loss: 0.9587 - val_accuracy: 0.6500\n",
      "Epoch 81/1000\n",
      "100/100 [==============================] - 78s 783ms/step - loss: 1.0475 - accuracy: 0.6212 - val_loss: 0.9703 - val_accuracy: 0.6465\n",
      "Epoch 82/1000\n",
      "100/100 [==============================] - 78s 781ms/step - loss: 1.0357 - accuracy: 0.6250 - val_loss: 0.9563 - val_accuracy: 0.6509\n",
      "Epoch 83/1000\n",
      "100/100 [==============================] - 78s 783ms/step - loss: 1.0465 - accuracy: 0.6097 - val_loss: 0.9462 - val_accuracy: 0.6614\n",
      "Epoch 84/1000\n",
      "100/100 [==============================] - 78s 780ms/step - loss: 1.0282 - accuracy: 0.6306 - val_loss: 0.9642 - val_accuracy: 0.6342\n",
      "Epoch 85/1000\n",
      "100/100 [==============================] - 78s 783ms/step - loss: 1.0323 - accuracy: 0.6228 - val_loss: 0.9804 - val_accuracy: 0.6465\n",
      "Epoch 86/1000\n",
      "100/100 [==============================] - 81s 805ms/step - loss: 1.0432 - accuracy: 0.6153 - val_loss: 0.9391 - val_accuracy: 0.6553\n",
      "Epoch 87/1000\n",
      "100/100 [==============================] - 79s 786ms/step - loss: 1.0332 - accuracy: 0.6331 - val_loss: 0.9388 - val_accuracy: 0.6588\n",
      "Epoch 88/1000\n",
      "100/100 [==============================] - 78s 781ms/step - loss: 1.0409 - accuracy: 0.6159 - val_loss: 0.9484 - val_accuracy: 0.6482\n",
      "Epoch 89/1000\n",
      "100/100 [==============================] - 78s 777ms/step - loss: 1.0286 - accuracy: 0.6257 - val_loss: 0.9127 - val_accuracy: 0.6737\n",
      "Epoch 90/1000\n",
      "100/100 [==============================] - 78s 781ms/step - loss: 1.0343 - accuracy: 0.6247 - val_loss: 0.9227 - val_accuracy: 0.6719\n",
      "Epoch 91/1000\n",
      "100/100 [==============================] - 78s 778ms/step - loss: 1.0303 - accuracy: 0.6178 - val_loss: 0.9050 - val_accuracy: 0.6693\n",
      "Epoch 92/1000\n",
      "100/100 [==============================] - 78s 776ms/step - loss: 1.0262 - accuracy: 0.6175 - val_loss: 0.9323 - val_accuracy: 0.6596\n",
      "Epoch 93/1000\n",
      "100/100 [==============================] - 78s 779ms/step - loss: 1.0291 - accuracy: 0.6275 - val_loss: 0.9380 - val_accuracy: 0.6623\n",
      "Epoch 94/1000\n",
      "100/100 [==============================] - 78s 776ms/step - loss: 1.0210 - accuracy: 0.6272 - val_loss: 0.9029 - val_accuracy: 0.6763\n",
      "Epoch 95/1000\n",
      "100/100 [==============================] - 78s 784ms/step - loss: 1.0207 - accuracy: 0.6269 - val_loss: 1.0069 - val_accuracy: 0.6211\n",
      "Epoch 96/1000\n",
      "100/100 [==============================] - 78s 778ms/step - loss: 1.0329 - accuracy: 0.6276 - val_loss: 0.9371 - val_accuracy: 0.6491\n",
      "Epoch 97/1000\n",
      "100/100 [==============================] - 78s 780ms/step - loss: 1.0218 - accuracy: 0.6306 - val_loss: 0.9195 - val_accuracy: 0.6623\n",
      "Epoch 98/1000\n",
      "100/100 [==============================] - 78s 780ms/step - loss: 1.0026 - accuracy: 0.6325 - val_loss: 0.9141 - val_accuracy: 0.6789\n",
      "Epoch 99/1000\n",
      "100/100 [==============================] - 78s 777ms/step - loss: 1.0002 - accuracy: 0.6411 - val_loss: 0.8965 - val_accuracy: 0.6886\n",
      "Epoch 100/1000\n",
      "100/100 [==============================] - 78s 782ms/step - loss: 1.0043 - accuracy: 0.6431 - val_loss: 0.9695 - val_accuracy: 0.6421\n",
      "Epoch 101/1000\n",
      "100/100 [==============================] - 78s 779ms/step - loss: 1.0031 - accuracy: 0.6372 - val_loss: 0.9128 - val_accuracy: 0.6596\n",
      "Epoch 102/1000\n",
      "100/100 [==============================] - 78s 776ms/step - loss: 1.0405 - accuracy: 0.6207 - val_loss: 0.9479 - val_accuracy: 0.6439\n",
      "Epoch 103/1000\n",
      "100/100 [==============================] - 78s 779ms/step - loss: 0.9960 - accuracy: 0.6306 - val_loss: 0.9606 - val_accuracy: 0.6491\n",
      "Epoch 104/1000\n",
      "100/100 [==============================] - 78s 778ms/step - loss: 0.9729 - accuracy: 0.6475 - val_loss: 0.8873 - val_accuracy: 0.6842\n",
      "Epoch 105/1000\n",
      "100/100 [==============================] - 78s 779ms/step - loss: 0.9937 - accuracy: 0.6345 - val_loss: 0.9278 - val_accuracy: 0.6509\n",
      "Epoch 106/1000\n",
      "100/100 [==============================] - 78s 779ms/step - loss: 1.0007 - accuracy: 0.6331 - val_loss: 0.9040 - val_accuracy: 0.6728\n",
      "Epoch 107/1000\n",
      "100/100 [==============================] - 78s 780ms/step - loss: 1.0122 - accuracy: 0.6225 - val_loss: 0.9100 - val_accuracy: 0.6632\n",
      "Epoch 108/1000\n",
      "100/100 [==============================] - 77s 773ms/step - loss: 0.9823 - accuracy: 0.6395 - val_loss: 0.9169 - val_accuracy: 0.6518\n",
      "Epoch 109/1000\n",
      "100/100 [==============================] - 77s 773ms/step - loss: 1.0000 - accuracy: 0.6397 - val_loss: 0.8820 - val_accuracy: 0.6860\n",
      "Epoch 110/1000\n",
      "100/100 [==============================] - 78s 777ms/step - loss: 0.9899 - accuracy: 0.6309 - val_loss: 0.9182 - val_accuracy: 0.6614\n",
      "Epoch 111/1000\n",
      "100/100 [==============================] - 78s 777ms/step - loss: 0.9987 - accuracy: 0.6279 - val_loss: 0.8867 - val_accuracy: 0.6719\n",
      "Epoch 112/1000\n",
      "100/100 [==============================] - 78s 779ms/step - loss: 1.0037 - accuracy: 0.6438 - val_loss: 0.9119 - val_accuracy: 0.6561\n",
      "Epoch 113/1000\n",
      "100/100 [==============================] - 78s 778ms/step - loss: 0.9769 - accuracy: 0.6481 - val_loss: 0.8826 - val_accuracy: 0.6930\n",
      "Epoch 114/1000\n",
      "100/100 [==============================] - 78s 782ms/step - loss: 0.9711 - accuracy: 0.6400 - val_loss: 0.9163 - val_accuracy: 0.6675\n",
      "Epoch 115/1000\n",
      "100/100 [==============================] - 78s 780ms/step - loss: 0.9889 - accuracy: 0.6383 - val_loss: 0.8964 - val_accuracy: 0.6675\n",
      "Epoch 116/1000\n",
      "100/100 [==============================] - 78s 777ms/step - loss: 0.9739 - accuracy: 0.6366 - val_loss: 0.8818 - val_accuracy: 0.6816\n",
      "Epoch 117/1000\n",
      "100/100 [==============================] - 77s 774ms/step - loss: 0.9797 - accuracy: 0.6375 - val_loss: 0.8912 - val_accuracy: 0.6781\n",
      "Epoch 118/1000\n",
      "100/100 [==============================] - 78s 777ms/step - loss: 0.9693 - accuracy: 0.6442 - val_loss: 0.8783 - val_accuracy: 0.6807\n",
      "Epoch 119/1000\n",
      "100/100 [==============================] - 78s 779ms/step - loss: 0.9657 - accuracy: 0.6519 - val_loss: 0.9254 - val_accuracy: 0.6412\n",
      "Epoch 120/1000\n",
      "100/100 [==============================] - 78s 779ms/step - loss: 0.9561 - accuracy: 0.6444 - val_loss: 0.8563 - val_accuracy: 0.6956\n",
      "Epoch 121/1000\n",
      "100/100 [==============================] - 78s 776ms/step - loss: 0.9753 - accuracy: 0.6364 - val_loss: 0.8730 - val_accuracy: 0.6789\n",
      "Epoch 122/1000\n",
      "100/100 [==============================] - 78s 782ms/step - loss: 0.9472 - accuracy: 0.6628 - val_loss: 0.9332 - val_accuracy: 0.6509\n",
      "Epoch 123/1000\n",
      "100/100 [==============================] - 78s 776ms/step - loss: 0.9487 - accuracy: 0.6575 - val_loss: 0.8890 - val_accuracy: 0.6772\n",
      "Epoch 124/1000\n",
      "100/100 [==============================] - 77s 775ms/step - loss: 0.9819 - accuracy: 0.6408 - val_loss: 0.9008 - val_accuracy: 0.6640\n",
      "Epoch 125/1000\n",
      "100/100 [==============================] - 78s 777ms/step - loss: 0.9591 - accuracy: 0.6525 - val_loss: 0.9279 - val_accuracy: 0.6491\n",
      "Epoch 126/1000\n",
      "100/100 [==============================] - 78s 775ms/step - loss: 0.9690 - accuracy: 0.6381 - val_loss: 0.8899 - val_accuracy: 0.6877\n",
      "Epoch 127/1000\n",
      "100/100 [==============================] - 78s 777ms/step - loss: 0.9691 - accuracy: 0.6496 - val_loss: 0.9499 - val_accuracy: 0.6404\n",
      "Epoch 128/1000\n",
      "100/100 [==============================] - 78s 781ms/step - loss: 0.9310 - accuracy: 0.6672 - val_loss: 0.8810 - val_accuracy: 0.6614\n",
      "Epoch 129/1000\n",
      "100/100 [==============================] - 78s 778ms/step - loss: 0.9387 - accuracy: 0.6572 - val_loss: 0.8873 - val_accuracy: 0.6842\n",
      "Epoch 130/1000\n",
      "100/100 [==============================] - 78s 777ms/step - loss: 0.9760 - accuracy: 0.6314 - val_loss: 0.8443 - val_accuracy: 0.7000\n",
      "Epoch 131/1000\n",
      "100/100 [==============================] - 78s 780ms/step - loss: 0.9416 - accuracy: 0.6534 - val_loss: 0.8397 - val_accuracy: 0.7123\n",
      "Epoch 132/1000\n",
      "100/100 [==============================] - 78s 779ms/step - loss: 0.9498 - accuracy: 0.6497 - val_loss: 0.8470 - val_accuracy: 0.7026\n",
      "Epoch 133/1000\n",
      "100/100 [==============================] - 78s 777ms/step - loss: 0.9500 - accuracy: 0.6578 - val_loss: 0.8843 - val_accuracy: 0.6719\n",
      "Epoch 134/1000\n",
      "100/100 [==============================] - 78s 776ms/step - loss: 0.9460 - accuracy: 0.6565 - val_loss: 0.8566 - val_accuracy: 0.6851\n",
      "Epoch 135/1000\n",
      "100/100 [==============================] - 78s 785ms/step - loss: 0.9491 - accuracy: 0.6603 - val_loss: 0.8977 - val_accuracy: 0.6719\n",
      "Epoch 136/1000\n",
      "100/100 [==============================] - 78s 776ms/step - loss: 0.9337 - accuracy: 0.6572 - val_loss: 0.8551 - val_accuracy: 0.6807\n",
      "Epoch 137/1000\n",
      "100/100 [==============================] - 78s 778ms/step - loss: 0.9243 - accuracy: 0.6512 - val_loss: 0.8419 - val_accuracy: 0.6965\n",
      "Epoch 138/1000\n",
      "100/100 [==============================] - 78s 779ms/step - loss: 0.9487 - accuracy: 0.6606 - val_loss: 0.8467 - val_accuracy: 0.6982\n",
      "Epoch 139/1000\n",
      "100/100 [==============================] - 78s 777ms/step - loss: 0.9360 - accuracy: 0.6603 - val_loss: 0.8896 - val_accuracy: 0.6693\n",
      "Epoch 140/1000\n",
      "100/100 [==============================] - 78s 778ms/step - loss: 0.9516 - accuracy: 0.6568 - val_loss: 0.9050 - val_accuracy: 0.6614\n",
      "Epoch 141/1000\n",
      "100/100 [==============================] - 78s 780ms/step - loss: 0.9496 - accuracy: 0.6562 - val_loss: 0.8631 - val_accuracy: 0.6877\n",
      "Epoch 142/1000\n",
      "100/100 [==============================] - 78s 780ms/step - loss: 0.9349 - accuracy: 0.6572 - val_loss: 0.8540 - val_accuracy: 0.6974\n",
      "Epoch 143/1000\n",
      "100/100 [==============================] - 78s 775ms/step - loss: 0.9362 - accuracy: 0.6662 - val_loss: 0.8616 - val_accuracy: 0.6974\n",
      "Epoch 144/1000\n",
      "100/100 [==============================] - 78s 776ms/step - loss: 0.9151 - accuracy: 0.6572 - val_loss: 0.8599 - val_accuracy: 0.6816\n",
      "Epoch 145/1000\n",
      "100/100 [==============================] - 78s 778ms/step - loss: 0.9367 - accuracy: 0.6575 - val_loss: 0.8282 - val_accuracy: 0.7026\n",
      "Epoch 146/1000\n",
      "100/100 [==============================] - 77s 773ms/step - loss: 0.9624 - accuracy: 0.6480 - val_loss: 0.8402 - val_accuracy: 0.6833\n",
      "Epoch 147/1000\n",
      "100/100 [==============================] - 78s 781ms/step - loss: 0.9681 - accuracy: 0.6450 - val_loss: 0.8684 - val_accuracy: 0.6965\n",
      "Epoch 148/1000\n",
      "100/100 [==============================] - 78s 776ms/step - loss: 0.9109 - accuracy: 0.6616 - val_loss: 0.8243 - val_accuracy: 0.6982\n",
      "Epoch 149/1000\n",
      "100/100 [==============================] - 77s 775ms/step - loss: 0.9182 - accuracy: 0.6596 - val_loss: 0.8913 - val_accuracy: 0.6789\n",
      "Epoch 150/1000\n",
      "100/100 [==============================] - 78s 778ms/step - loss: 0.9283 - accuracy: 0.6650 - val_loss: 0.8926 - val_accuracy: 0.6789\n",
      "Epoch 151/1000\n",
      "100/100 [==============================] - 78s 779ms/step - loss: 0.9234 - accuracy: 0.6631 - val_loss: 0.8714 - val_accuracy: 0.6860\n",
      "Epoch 152/1000\n",
      "100/100 [==============================] - 79s 786ms/step - loss: 0.9205 - accuracy: 0.6625 - val_loss: 0.8613 - val_accuracy: 0.6842\n",
      "Epoch 153/1000\n",
      "100/100 [==============================] - 77s 772ms/step - loss: 0.9137 - accuracy: 0.6631 - val_loss: 0.8667 - val_accuracy: 0.6842\n",
      "Epoch 154/1000\n",
      "100/100 [==============================] - 78s 778ms/step - loss: 0.9264 - accuracy: 0.6556 - val_loss: 0.8335 - val_accuracy: 0.7044\n",
      "Epoch 155/1000\n",
      "100/100 [==============================] - 78s 779ms/step - loss: 0.9220 - accuracy: 0.6706 - val_loss: 0.8038 - val_accuracy: 0.7079\n",
      "Epoch 156/1000\n",
      "100/100 [==============================] - 77s 773ms/step - loss: 0.9109 - accuracy: 0.6609 - val_loss: 0.8682 - val_accuracy: 0.6868\n",
      "Epoch 157/1000\n",
      "100/100 [==============================] - 78s 778ms/step - loss: 0.9225 - accuracy: 0.6691 - val_loss: 0.8523 - val_accuracy: 0.6763\n",
      "Epoch 158/1000\n",
      "100/100 [==============================] - 78s 780ms/step - loss: 0.8946 - accuracy: 0.6750 - val_loss: 0.8894 - val_accuracy: 0.6579\n",
      "Epoch 159/1000\n",
      "100/100 [==============================] - 78s 779ms/step - loss: 0.9220 - accuracy: 0.6675 - val_loss: 0.8276 - val_accuracy: 0.7061\n",
      "Epoch 160/1000\n",
      "100/100 [==============================] - 78s 781ms/step - loss: 0.9025 - accuracy: 0.6644 - val_loss: 0.8137 - val_accuracy: 0.6921\n",
      "Epoch 161/1000\n",
      "100/100 [==============================] - 78s 775ms/step - loss: 0.9082 - accuracy: 0.6747 - val_loss: 0.8341 - val_accuracy: 0.7035\n",
      "Epoch 162/1000\n",
      "100/100 [==============================] - 78s 780ms/step - loss: 0.8992 - accuracy: 0.6710 - val_loss: 0.8205 - val_accuracy: 0.6974\n",
      "Epoch 163/1000\n",
      "100/100 [==============================] - 78s 781ms/step - loss: 0.9079 - accuracy: 0.6706 - val_loss: 0.8476 - val_accuracy: 0.6965\n",
      "Epoch 164/1000\n",
      "100/100 [==============================] - 78s 780ms/step - loss: 0.9190 - accuracy: 0.6703 - val_loss: 0.8923 - val_accuracy: 0.6596\n",
      "Epoch 165/1000\n",
      "100/100 [==============================] - 77s 771ms/step - loss: 0.9115 - accuracy: 0.6596 - val_loss: 0.8337 - val_accuracy: 0.6921\n",
      "Epoch 166/1000\n",
      "100/100 [==============================] - 78s 776ms/step - loss: 0.8916 - accuracy: 0.6712 - val_loss: 0.8418 - val_accuracy: 0.6991\n",
      "Epoch 167/1000\n",
      "100/100 [==============================] - 78s 777ms/step - loss: 0.8840 - accuracy: 0.6781 - val_loss: 0.8390 - val_accuracy: 0.6974\n",
      "Epoch 168/1000\n",
      "100/100 [==============================] - 77s 774ms/step - loss: 0.9232 - accuracy: 0.6641 - val_loss: 0.8294 - val_accuracy: 0.6860\n",
      "Epoch 169/1000\n",
      "100/100 [==============================] - 82s 820ms/step - loss: 0.8985 - accuracy: 0.6719 - val_loss: 0.8066 - val_accuracy: 0.6912\n",
      "Epoch 170/1000\n",
      "100/100 [==============================] - 77s 774ms/step - loss: 0.9353 - accuracy: 0.6503 - val_loss: 0.8206 - val_accuracy: 0.7053\n",
      "Epoch 171/1000\n",
      "100/100 [==============================] - 78s 776ms/step - loss: 0.8824 - accuracy: 0.6859 - val_loss: 0.7995 - val_accuracy: 0.7096\n",
      "Epoch 172/1000\n",
      "100/100 [==============================] - 77s 775ms/step - loss: 0.8641 - accuracy: 0.6769 - val_loss: 0.8050 - val_accuracy: 0.7026\n",
      "Epoch 173/1000\n",
      "100/100 [==============================] - 77s 773ms/step - loss: 0.9118 - accuracy: 0.6637 - val_loss: 0.8425 - val_accuracy: 0.6956\n",
      "Epoch 174/1000\n",
      "100/100 [==============================] - 78s 780ms/step - loss: 0.9390 - accuracy: 0.6575 - val_loss: 0.8549 - val_accuracy: 0.6789\n",
      "Epoch 175/1000\n",
      "100/100 [==============================] - 78s 777ms/step - loss: 0.8800 - accuracy: 0.6741 - val_loss: 0.8050 - val_accuracy: 0.7079\n",
      "Epoch 176/1000\n",
      "100/100 [==============================] - 78s 784ms/step - loss: 0.9100 - accuracy: 0.6603 - val_loss: 0.8383 - val_accuracy: 0.6947\n",
      "Epoch 177/1000\n",
      "100/100 [==============================] - 78s 781ms/step - loss: 0.8804 - accuracy: 0.6791 - val_loss: 0.8130 - val_accuracy: 0.6947\n",
      "Epoch 178/1000\n",
      "100/100 [==============================] - 78s 778ms/step - loss: 0.8593 - accuracy: 0.6854 - val_loss: 0.8081 - val_accuracy: 0.7079\n",
      "Epoch 179/1000\n",
      "100/100 [==============================] - 78s 778ms/step - loss: 0.9052 - accuracy: 0.6697 - val_loss: 0.8119 - val_accuracy: 0.7105\n",
      "Epoch 180/1000\n",
      "100/100 [==============================] - 78s 778ms/step - loss: 0.8720 - accuracy: 0.6816 - val_loss: 0.8059 - val_accuracy: 0.7096\n",
      "Epoch 181/1000\n",
      "100/100 [==============================] - 78s 779ms/step - loss: 0.8475 - accuracy: 0.6961 - val_loss: 0.8509 - val_accuracy: 0.6939\n",
      "Epoch 182/1000\n",
      "100/100 [==============================] - 78s 779ms/step - loss: 0.8936 - accuracy: 0.6747 - val_loss: 0.8231 - val_accuracy: 0.6904\n",
      "Epoch 183/1000\n",
      "100/100 [==============================] - 77s 774ms/step - loss: 0.8786 - accuracy: 0.6784 - val_loss: 0.8241 - val_accuracy: 0.6991\n",
      "Epoch 184/1000\n",
      "100/100 [==============================] - 77s 774ms/step - loss: 0.8901 - accuracy: 0.6794 - val_loss: 0.7854 - val_accuracy: 0.7079\n",
      "Epoch 185/1000\n",
      "100/100 [==============================] - 78s 775ms/step - loss: 0.8914 - accuracy: 0.6809 - val_loss: 0.7957 - val_accuracy: 0.7105\n",
      "Epoch 186/1000\n",
      "100/100 [==============================] - 82s 819ms/step - loss: 0.8899 - accuracy: 0.6762 - val_loss: 0.7894 - val_accuracy: 0.7193\n",
      "Epoch 187/1000\n",
      "100/100 [==============================] - 77s 775ms/step - loss: 0.8709 - accuracy: 0.6756 - val_loss: 0.8109 - val_accuracy: 0.7000\n",
      "Epoch 188/1000\n",
      "100/100 [==============================] - 77s 773ms/step - loss: 0.8652 - accuracy: 0.6713 - val_loss: 0.8045 - val_accuracy: 0.7061\n",
      "Epoch 189/1000\n",
      "100/100 [==============================] - 78s 780ms/step - loss: 0.8926 - accuracy: 0.6712 - val_loss: 0.8506 - val_accuracy: 0.6763\n",
      "Epoch 190/1000\n",
      "100/100 [==============================] - 77s 775ms/step - loss: 0.8839 - accuracy: 0.6797 - val_loss: 0.8138 - val_accuracy: 0.7009\n",
      "Epoch 191/1000\n",
      "100/100 [==============================] - 77s 774ms/step - loss: 0.8545 - accuracy: 0.6904 - val_loss: 0.8536 - val_accuracy: 0.6754\n",
      "Epoch 192/1000\n",
      "100/100 [==============================] - 78s 778ms/step - loss: 0.8663 - accuracy: 0.6888 - val_loss: 0.8970 - val_accuracy: 0.6474\n",
      "Epoch 193/1000\n",
      "100/100 [==============================] - 78s 779ms/step - loss: 0.8769 - accuracy: 0.6831 - val_loss: 0.8108 - val_accuracy: 0.7088\n",
      "Epoch 194/1000\n",
      "100/100 [==============================] - 78s 776ms/step - loss: 0.8822 - accuracy: 0.6719 - val_loss: 0.8121 - val_accuracy: 0.7184\n",
      "Epoch 195/1000\n",
      "100/100 [==============================] - 78s 782ms/step - loss: 0.8707 - accuracy: 0.6922 - val_loss: 0.8140 - val_accuracy: 0.7009\n",
      "Epoch 196/1000\n",
      "100/100 [==============================] - 78s 779ms/step - loss: 0.8864 - accuracy: 0.6784 - val_loss: 0.7912 - val_accuracy: 0.7044\n",
      "Epoch 197/1000\n",
      "100/100 [==============================] - 77s 773ms/step - loss: 0.8597 - accuracy: 0.6832 - val_loss: 0.7780 - val_accuracy: 0.7123\n",
      "Epoch 198/1000\n",
      "100/100 [==============================] - 78s 778ms/step - loss: 0.8679 - accuracy: 0.6722 - val_loss: 0.8077 - val_accuracy: 0.7140\n",
      "Epoch 199/1000\n",
      "100/100 [==============================] - 78s 780ms/step - loss: 0.8621 - accuracy: 0.6856 - val_loss: 0.7989 - val_accuracy: 0.7079\n",
      "Epoch 200/1000\n",
      "100/100 [==============================] - 78s 776ms/step - loss: 0.8837 - accuracy: 0.6801 - val_loss: 0.7823 - val_accuracy: 0.7149\n",
      "Epoch 201/1000\n",
      "100/100 [==============================] - 78s 780ms/step - loss: 0.8518 - accuracy: 0.6869 - val_loss: 0.8154 - val_accuracy: 0.6947\n",
      "Epoch 202/1000\n",
      "100/100 [==============================] - 78s 776ms/step - loss: 0.8598 - accuracy: 0.6812 - val_loss: 0.8375 - val_accuracy: 0.6912\n",
      "Epoch 203/1000\n",
      "100/100 [==============================] - 78s 779ms/step - loss: 0.8687 - accuracy: 0.6838 - val_loss: 0.7842 - val_accuracy: 0.7167\n",
      "Epoch 204/1000\n",
      "100/100 [==============================] - 78s 782ms/step - loss: 0.8413 - accuracy: 0.6956 - val_loss: 0.7980 - val_accuracy: 0.7079\n",
      "Epoch 205/1000\n",
      "100/100 [==============================] - 78s 777ms/step - loss: 0.8548 - accuracy: 0.6850 - val_loss: 0.7858 - val_accuracy: 0.7018\n",
      "Epoch 206/1000\n",
      "100/100 [==============================] - 78s 778ms/step - loss: 0.8668 - accuracy: 0.6919 - val_loss: 0.8049 - val_accuracy: 0.7018\n",
      "Epoch 207/1000\n",
      "100/100 [==============================] - 78s 776ms/step - loss: 0.8648 - accuracy: 0.6794 - val_loss: 0.7664 - val_accuracy: 0.7211\n",
      "Epoch 208/1000\n",
      "100/100 [==============================] - 78s 778ms/step - loss: 0.8852 - accuracy: 0.6803 - val_loss: 0.8588 - val_accuracy: 0.6719\n",
      "Epoch 209/1000\n",
      "100/100 [==============================] - 78s 776ms/step - loss: 0.8512 - accuracy: 0.6831 - val_loss: 0.8219 - val_accuracy: 0.6939\n",
      "Epoch 210/1000\n",
      "100/100 [==============================] - 78s 778ms/step - loss: 0.8394 - accuracy: 0.6807 - val_loss: 0.8374 - val_accuracy: 0.6772\n",
      "Epoch 211/1000\n",
      "100/100 [==============================] - 78s 779ms/step - loss: 0.8722 - accuracy: 0.6812 - val_loss: 0.7964 - val_accuracy: 0.7070\n",
      "Epoch 212/1000\n",
      "100/100 [==============================] - 78s 779ms/step - loss: 0.8414 - accuracy: 0.6975 - val_loss: 0.8352 - val_accuracy: 0.6956\n",
      "Epoch 213/1000\n",
      "100/100 [==============================] - 78s 779ms/step - loss: 0.8742 - accuracy: 0.6785 - val_loss: 0.7907 - val_accuracy: 0.7193\n",
      "Epoch 214/1000\n",
      "100/100 [==============================] - 78s 782ms/step - loss: 0.8461 - accuracy: 0.6981 - val_loss: 0.8017 - val_accuracy: 0.7061\n",
      "Epoch 215/1000\n",
      "100/100 [==============================] - 77s 773ms/step - loss: 0.8598 - accuracy: 0.6862 - val_loss: 0.8208 - val_accuracy: 0.6895\n",
      "Epoch 216/1000\n",
      "100/100 [==============================] - 77s 774ms/step - loss: 0.8416 - accuracy: 0.6958 - val_loss: 0.8023 - val_accuracy: 0.7026\n",
      "Epoch 217/1000\n",
      "100/100 [==============================] - 78s 777ms/step - loss: 0.8690 - accuracy: 0.6822 - val_loss: 0.8141 - val_accuracy: 0.7132\n",
      "Epoch 218/1000\n",
      "100/100 [==============================] - 78s 780ms/step - loss: 0.8504 - accuracy: 0.6844 - val_loss: 0.8105 - val_accuracy: 0.7061\n",
      "Epoch 219/1000\n",
      "100/100 [==============================] - 78s 776ms/step - loss: 0.8580 - accuracy: 0.6857 - val_loss: 0.7902 - val_accuracy: 0.7044\n",
      "Epoch 220/1000\n",
      "100/100 [==============================] - 80s 804ms/step - loss: 0.8442 - accuracy: 0.6913 - val_loss: 0.7802 - val_accuracy: 0.7246\n",
      "Epoch 221/1000\n",
      "100/100 [==============================] - 78s 777ms/step - loss: 0.8627 - accuracy: 0.6822 - val_loss: 0.7780 - val_accuracy: 0.7289\n",
      "Epoch 222/1000\n",
      "100/100 [==============================] - 78s 777ms/step - loss: 0.8574 - accuracy: 0.6901 - val_loss: 0.7823 - val_accuracy: 0.7202\n",
      "Epoch 223/1000\n",
      "100/100 [==============================] - 78s 776ms/step - loss: 0.8212 - accuracy: 0.7072 - val_loss: 0.7705 - val_accuracy: 0.7228\n",
      "Epoch 224/1000\n",
      "100/100 [==============================] - 78s 778ms/step - loss: 0.8587 - accuracy: 0.6853 - val_loss: 0.7850 - val_accuracy: 0.7175\n",
      "Epoch 225/1000\n",
      "100/100 [==============================] - 78s 780ms/step - loss: 0.8145 - accuracy: 0.7066 - val_loss: 0.8091 - val_accuracy: 0.7061\n",
      "Epoch 226/1000\n",
      "100/100 [==============================] - 78s 777ms/step - loss: 0.8312 - accuracy: 0.6920 - val_loss: 0.7722 - val_accuracy: 0.7184\n",
      "Epoch 227/1000\n",
      "100/100 [==============================] - 78s 778ms/step - loss: 0.8225 - accuracy: 0.7078 - val_loss: 0.7870 - val_accuracy: 0.6974\n",
      "Epoch 228/1000\n",
      "100/100 [==============================] - 78s 779ms/step - loss: 0.8447 - accuracy: 0.6894 - val_loss: 0.7886 - val_accuracy: 0.7140\n",
      "Epoch 229/1000\n",
      "100/100 [==============================] - 78s 779ms/step - loss: 0.8510 - accuracy: 0.6886 - val_loss: 0.7538 - val_accuracy: 0.7158\n",
      "Epoch 230/1000\n",
      "100/100 [==============================] - 78s 777ms/step - loss: 0.8393 - accuracy: 0.6941 - val_loss: 0.8238 - val_accuracy: 0.7061\n",
      "Epoch 231/1000\n",
      "100/100 [==============================] - 78s 777ms/step - loss: 0.8255 - accuracy: 0.6956 - val_loss: 0.7797 - val_accuracy: 0.7053\n",
      "Epoch 232/1000\n",
      "100/100 [==============================] - 77s 775ms/step - loss: 0.8241 - accuracy: 0.6999 - val_loss: 0.7868 - val_accuracy: 0.7105\n",
      "Epoch 233/1000\n",
      "100/100 [==============================] - 78s 777ms/step - loss: 0.8278 - accuracy: 0.7006 - val_loss: 0.8245 - val_accuracy: 0.6939\n",
      "Epoch 234/1000\n",
      "100/100 [==============================] - 78s 777ms/step - loss: 0.8501 - accuracy: 0.6878 - val_loss: 0.7985 - val_accuracy: 0.7114\n",
      "Epoch 235/1000\n",
      "100/100 [==============================] - 78s 778ms/step - loss: 0.8606 - accuracy: 0.6835 - val_loss: 0.7875 - val_accuracy: 0.7088\n",
      "Epoch 236/1000\n",
      "100/100 [==============================] - 78s 779ms/step - loss: 0.8375 - accuracy: 0.6944 - val_loss: 0.7683 - val_accuracy: 0.7246\n",
      "Epoch 237/1000\n",
      "100/100 [==============================] - 78s 783ms/step - loss: 0.8241 - accuracy: 0.7025 - val_loss: 0.7839 - val_accuracy: 0.6982\n",
      "Epoch 238/1000\n",
      "100/100 [==============================] - 77s 775ms/step - loss: 0.8002 - accuracy: 0.7043 - val_loss: 0.8003 - val_accuracy: 0.7026\n",
      "Epoch 239/1000\n",
      "100/100 [==============================] - 78s 776ms/step - loss: 0.8585 - accuracy: 0.6725 - val_loss: 0.7542 - val_accuracy: 0.7281\n",
      "Epoch 240/1000\n",
      "100/100 [==============================] - 78s 775ms/step - loss: 0.8199 - accuracy: 0.7081 - val_loss: 0.7971 - val_accuracy: 0.7035\n",
      "Epoch 241/1000\n",
      "100/100 [==============================] - 77s 771ms/step - loss: 0.8140 - accuracy: 0.7055 - val_loss: 0.7614 - val_accuracy: 0.7281\n",
      "Epoch 242/1000\n",
      "100/100 [==============================] - 78s 780ms/step - loss: 0.8370 - accuracy: 0.6919 - val_loss: 0.7810 - val_accuracy: 0.7088\n",
      "Epoch 243/1000\n",
      "100/100 [==============================] - 78s 778ms/step - loss: 0.8310 - accuracy: 0.6884 - val_loss: 0.7597 - val_accuracy: 0.7167\n",
      "Epoch 244/1000\n",
      "100/100 [==============================] - 78s 782ms/step - loss: 0.8371 - accuracy: 0.6981 - val_loss: 0.7645 - val_accuracy: 0.7184\n",
      "Epoch 245/1000\n",
      "100/100 [==============================] - 78s 776ms/step - loss: 0.8533 - accuracy: 0.6857 - val_loss: 0.8043 - val_accuracy: 0.7105\n",
      "Epoch 246/1000\n",
      "100/100 [==============================] - 78s 776ms/step - loss: 0.8383 - accuracy: 0.6888 - val_loss: 0.8145 - val_accuracy: 0.6851\n",
      "Epoch 247/1000\n",
      "100/100 [==============================] - 78s 777ms/step - loss: 0.7946 - accuracy: 0.7116 - val_loss: 0.7631 - val_accuracy: 0.7096\n",
      "Epoch 248/1000\n",
      "100/100 [==============================] - 78s 777ms/step - loss: 0.8138 - accuracy: 0.7011 - val_loss: 0.7841 - val_accuracy: 0.7140\n",
      "Epoch 249/1000\n",
      "100/100 [==============================] - 78s 776ms/step - loss: 0.8324 - accuracy: 0.6978 - val_loss: 0.8452 - val_accuracy: 0.6851\n",
      "Epoch 250/1000\n",
      "100/100 [==============================] - 78s 775ms/step - loss: 0.8130 - accuracy: 0.7106 - val_loss: 0.7495 - val_accuracy: 0.7246\n",
      "Epoch 251/1000\n",
      "100/100 [==============================] - 78s 776ms/step - loss: 0.8454 - accuracy: 0.6914 - val_loss: 0.7712 - val_accuracy: 0.7263\n",
      "Epoch 252/1000\n",
      "100/100 [==============================] - 78s 778ms/step - loss: 0.8374 - accuracy: 0.6922 - val_loss: 0.8103 - val_accuracy: 0.7009\n",
      "Epoch 253/1000\n",
      "100/100 [==============================] - 78s 779ms/step - loss: 0.7981 - accuracy: 0.7141 - val_loss: 0.7537 - val_accuracy: 0.7246\n",
      "Epoch 254/1000\n",
      "100/100 [==============================] - 78s 782ms/step - loss: 0.8051 - accuracy: 0.7030 - val_loss: 0.7590 - val_accuracy: 0.7246\n",
      "Epoch 255/1000\n",
      "100/100 [==============================] - 78s 777ms/step - loss: 0.8183 - accuracy: 0.6994 - val_loss: 0.8004 - val_accuracy: 0.7009\n",
      "Epoch 256/1000\n",
      "100/100 [==============================] - 78s 777ms/step - loss: 0.8088 - accuracy: 0.7013 - val_loss: 0.7415 - val_accuracy: 0.7298\n",
      "Epoch 257/1000\n",
      "100/100 [==============================] - 77s 773ms/step - loss: 0.8264 - accuracy: 0.6961 - val_loss: 0.8155 - val_accuracy: 0.7009\n",
      "Epoch 258/1000\n",
      "100/100 [==============================] - 77s 774ms/step - loss: 0.8122 - accuracy: 0.7038 - val_loss: 0.7438 - val_accuracy: 0.7263\n",
      "Epoch 259/1000\n",
      "100/100 [==============================] - 78s 778ms/step - loss: 0.8291 - accuracy: 0.6956 - val_loss: 0.7824 - val_accuracy: 0.7079\n",
      "Epoch 260/1000\n",
      "100/100 [==============================] - 77s 773ms/step - loss: 0.8388 - accuracy: 0.6870 - val_loss: 0.7883 - val_accuracy: 0.7123\n",
      "Epoch 261/1000\n",
      "100/100 [==============================] - 77s 775ms/step - loss: 0.8210 - accuracy: 0.7009 - val_loss: 0.7691 - val_accuracy: 0.7193\n",
      "Epoch 262/1000\n",
      "100/100 [==============================] - 77s 775ms/step - loss: 0.8202 - accuracy: 0.6944 - val_loss: 0.8399 - val_accuracy: 0.6886\n",
      "Epoch 263/1000\n",
      "100/100 [==============================] - 81s 808ms/step - loss: 0.8319 - accuracy: 0.6950 - val_loss: 0.7535 - val_accuracy: 0.7254\n",
      "Epoch 264/1000\n",
      "100/100 [==============================] - 78s 776ms/step - loss: 0.8155 - accuracy: 0.6989 - val_loss: 0.7837 - val_accuracy: 0.7070\n",
      "Epoch 265/1000\n",
      "100/100 [==============================] - 78s 777ms/step - loss: 0.8207 - accuracy: 0.6997 - val_loss: 0.7954 - val_accuracy: 0.6956\n",
      "Epoch 266/1000\n",
      "100/100 [==============================] - 78s 777ms/step - loss: 0.8023 - accuracy: 0.7066 - val_loss: 0.7407 - val_accuracy: 0.7254\n",
      "Epoch 267/1000\n",
      "100/100 [==============================] - 78s 777ms/step - loss: 0.8437 - accuracy: 0.6917 - val_loss: 0.7755 - val_accuracy: 0.7088\n",
      "Epoch 268/1000\n",
      "100/100 [==============================] - 78s 777ms/step - loss: 0.7877 - accuracy: 0.7128 - val_loss: 0.7617 - val_accuracy: 0.7281\n",
      "Epoch 269/1000\n",
      "100/100 [==============================] - 77s 773ms/step - loss: 0.8216 - accuracy: 0.6941 - val_loss: 0.7391 - val_accuracy: 0.7325\n",
      "Epoch 270/1000\n",
      "100/100 [==============================] - 77s 775ms/step - loss: 0.8036 - accuracy: 0.7052 - val_loss: 0.7426 - val_accuracy: 0.7272\n",
      "Epoch 271/1000\n",
      "100/100 [==============================] - 77s 773ms/step - loss: 0.7971 - accuracy: 0.7113 - val_loss: 0.7645 - val_accuracy: 0.7246\n",
      "Epoch 272/1000\n",
      "100/100 [==============================] - 77s 775ms/step - loss: 0.8317 - accuracy: 0.6966 - val_loss: 0.7792 - val_accuracy: 0.7096\n",
      "Epoch 273/1000\n",
      "100/100 [==============================] - 78s 777ms/step - loss: 0.8084 - accuracy: 0.7063 - val_loss: 0.7502 - val_accuracy: 0.7263\n",
      "Epoch 274/1000\n",
      "100/100 [==============================] - 78s 781ms/step - loss: 0.7851 - accuracy: 0.7159 - val_loss: 0.7375 - val_accuracy: 0.7307\n",
      "Epoch 275/1000\n",
      "100/100 [==============================] - 78s 777ms/step - loss: 0.8021 - accuracy: 0.7034 - val_loss: 0.7592 - val_accuracy: 0.7254\n",
      "Epoch 276/1000\n",
      "100/100 [==============================] - 78s 777ms/step - loss: 0.8227 - accuracy: 0.7027 - val_loss: 0.7374 - val_accuracy: 0.7342\n",
      "Epoch 277/1000\n",
      "100/100 [==============================] - 78s 776ms/step - loss: 0.7860 - accuracy: 0.7209 - val_loss: 0.7797 - val_accuracy: 0.7184\n",
      "Epoch 278/1000\n",
      "100/100 [==============================] - 78s 779ms/step - loss: 0.8038 - accuracy: 0.7106 - val_loss: 0.7778 - val_accuracy: 0.7175\n",
      "Epoch 279/1000\n",
      "100/100 [==============================] - 78s 776ms/step - loss: 0.8302 - accuracy: 0.6886 - val_loss: 0.7464 - val_accuracy: 0.7175\n",
      "Epoch 280/1000\n",
      "100/100 [==============================] - 78s 778ms/step - loss: 0.8021 - accuracy: 0.7059 - val_loss: 0.7369 - val_accuracy: 0.7175\n",
      "Epoch 281/1000\n",
      "100/100 [==============================] - 78s 780ms/step - loss: 0.8135 - accuracy: 0.6988 - val_loss: 0.7501 - val_accuracy: 0.7167\n",
      "Epoch 282/1000\n",
      "100/100 [==============================] - 78s 778ms/step - loss: 0.7853 - accuracy: 0.7141 - val_loss: 0.7376 - val_accuracy: 0.7333\n",
      "Epoch 283/1000\n",
      "100/100 [==============================] - 78s 776ms/step - loss: 0.7974 - accuracy: 0.7150 - val_loss: 0.7798 - val_accuracy: 0.7228\n",
      "Epoch 284/1000\n",
      "100/100 [==============================] - 77s 774ms/step - loss: 0.8237 - accuracy: 0.6928 - val_loss: 0.8137 - val_accuracy: 0.6939\n",
      "Epoch 285/1000\n",
      "100/100 [==============================] - 77s 774ms/step - loss: 0.7865 - accuracy: 0.7116 - val_loss: 0.7818 - val_accuracy: 0.7088\n",
      "Epoch 286/1000\n",
      "100/100 [==============================] - 77s 774ms/step - loss: 0.8010 - accuracy: 0.7030 - val_loss: 0.7689 - val_accuracy: 0.7114\n",
      "Epoch 287/1000\n",
      "100/100 [==============================] - 78s 775ms/step - loss: 0.8272 - accuracy: 0.6900 - val_loss: 0.7945 - val_accuracy: 0.7053\n",
      "Epoch 288/1000\n",
      "100/100 [==============================] - 78s 776ms/step - loss: 0.7989 - accuracy: 0.7116 - val_loss: 0.7643 - val_accuracy: 0.7132\n",
      "Epoch 289/1000\n",
      "100/100 [==============================] - 78s 779ms/step - loss: 0.7883 - accuracy: 0.7099 - val_loss: 0.7703 - val_accuracy: 0.7096\n",
      "Epoch 290/1000\n",
      "100/100 [==============================] - 77s 775ms/step - loss: 0.8155 - accuracy: 0.7044 - val_loss: 0.7565 - val_accuracy: 0.7149\n",
      "Epoch 291/1000\n",
      "100/100 [==============================] - 77s 774ms/step - loss: 0.7686 - accuracy: 0.7244 - val_loss: 0.7555 - val_accuracy: 0.7316\n",
      "Epoch 292/1000\n",
      "100/100 [==============================] - 78s 779ms/step - loss: 0.8047 - accuracy: 0.6942 - val_loss: 0.7479 - val_accuracy: 0.7263\n",
      "Epoch 293/1000\n",
      "100/100 [==============================] - 78s 776ms/step - loss: 0.8231 - accuracy: 0.6894 - val_loss: 0.7299 - val_accuracy: 0.7430\n",
      "Epoch 294/1000\n",
      "100/100 [==============================] - 78s 779ms/step - loss: 0.8061 - accuracy: 0.7063 - val_loss: 0.7589 - val_accuracy: 0.7307\n",
      "Epoch 295/1000\n",
      "100/100 [==============================] - 77s 773ms/step - loss: 0.7880 - accuracy: 0.7096 - val_loss: 0.7728 - val_accuracy: 0.7149\n",
      "Epoch 296/1000\n",
      "100/100 [==============================] - 78s 778ms/step - loss: 0.7863 - accuracy: 0.7084 - val_loss: 0.7462 - val_accuracy: 0.7298\n",
      "Epoch 297/1000\n",
      "100/100 [==============================] - 78s 779ms/step - loss: 0.7885 - accuracy: 0.7066 - val_loss: 0.7688 - val_accuracy: 0.7175\n",
      "Epoch 298/1000\n",
      "100/100 [==============================] - 78s 778ms/step - loss: 0.8054 - accuracy: 0.7018 - val_loss: 0.7856 - val_accuracy: 0.7114\n",
      "Epoch 299/1000\n",
      "100/100 [==============================] - 77s 774ms/step - loss: 0.8132 - accuracy: 0.7028 - val_loss: 0.7519 - val_accuracy: 0.7167\n",
      "Epoch 300/1000\n",
      "100/100 [==============================] - 77s 774ms/step - loss: 0.7855 - accuracy: 0.7056 - val_loss: 0.7476 - val_accuracy: 0.7307\n",
      "Epoch 301/1000\n",
      "100/100 [==============================] - 77s 773ms/step - loss: 0.7740 - accuracy: 0.7175 - val_loss: 0.7457 - val_accuracy: 0.7193\n",
      "Epoch 302/1000\n",
      "100/100 [==============================] - 77s 773ms/step - loss: 0.7678 - accuracy: 0.7200 - val_loss: 0.7214 - val_accuracy: 0.7298\n",
      "Epoch 303/1000\n",
      "100/100 [==============================] - 81s 807ms/step - loss: 0.7843 - accuracy: 0.7116 - val_loss: 0.7839 - val_accuracy: 0.7079\n",
      "Epoch 304/1000\n",
      "100/100 [==============================] - 77s 774ms/step - loss: 0.8163 - accuracy: 0.7109 - val_loss: 0.7400 - val_accuracy: 0.7360\n",
      "Epoch 305/1000\n",
      "100/100 [==============================] - 77s 774ms/step - loss: 0.7756 - accuracy: 0.7219 - val_loss: 0.7918 - val_accuracy: 0.7140\n",
      "Epoch 306/1000\n",
      " 70/100 [====================>.........] - ETA: 17s - loss: 0.7793 - accuracy: 0.7094"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-3d0c19c7331e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         validation_data=validation_generator)\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hist= vgg_model.fit(\n",
    "        my_gen(train_generator),\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        epochs=epoch,\n",
    "        validation_data=validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vgg_history = vgg_model.fit(X_train, y_train, epochs=10,steps_per_epoch=50,validation_data=(X_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_loss, test_acc = vgg_model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "# print('\\nTest accuracy {:5.2f}%'.format(100*test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loss = vgg_history.history['loss']\n",
    "test_loss = vgg_history.history['val_loss']\n",
    "\n",
    "epoch_count = range(1,len(training_loss)+1)\n",
    "\n",
    "plt.plot(epoch_count,training_loss,'r--')\n",
    "plt.plot(epoch_count,test_loss,'b-')\n",
    "plt.legend(['Training Loss', 'Validation Loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = vgg_history.history['accuracy']\n",
    "val_acc = vgg_history.history['val_accuracy']\n",
    "\n",
    "epoch_count = range(1,len(training_loss)+1)\n",
    "\n",
    "plt.plot(acc, 'r--', label='Training Accuracy')\n",
    "plt.plot(val_acc, 'b-', label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Undersample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
